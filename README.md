# LLM-GPU-Calc

A simple and efficient tool to calculate GPU memory requirements for serving large language models (LLMs). It provides detailed insights into memory usage, including model weights, KV cache, and activation peaks, helping optimize resource allocation for inference pipelines.
